{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47844310.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "N,D,H=64,1000,100\n",
    "x= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "y= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "\n",
    "w1= tf.placeholder(tf.float32 , shape=(D,H))\n",
    "w2= tf.placeholder(tf.float32 , shape=(H,D))\n",
    "\n",
    "h=tf.maximum(tf.matmul(x,w1),0)\n",
    "y_pred=tf.matmul(h,w2)\n",
    "diff=y_pred-y\n",
    "loss=tf.reduce_mean(tf.reduce_sum(diff**2,axis=1))\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "with tf.Session() as sess:\n",
    "    values ={x:np.random.randn(N,D),\n",
    "             w1:np.random.randn(D,H),\n",
    "             w2:np.random.randn(H,D),\n",
    "             y:np.random.randn(N,D)}\n",
    "    out=sess.run(loss,feed_dict=values)\n",
    "    loss=out\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47127600.0\n",
      "47127720.0\n",
      "47127850.0\n",
      "47127970.0\n",
      "47128090.0\n",
      "47128216.0\n",
      "47128344.0\n",
      "47128464.0\n",
      "47128590.0\n",
      "47128704.0\n",
      "47128830.0\n",
      "47128948.0\n",
      "47129080.0\n",
      "47129210.0\n",
      "47129330.0\n",
      "47129450.0\n",
      "47129576.0\n",
      "47129696.0\n",
      "47129820.0\n",
      "47129936.0\n",
      "47130064.0\n",
      "47130190.0\n",
      "47130316.0\n",
      "47130440.0\n",
      "47130570.0\n",
      "47130690.0\n",
      "47130824.0\n",
      "47130944.0\n",
      "47131068.0\n",
      "47131188.0\n",
      "47131320.0\n",
      "47131450.0\n",
      "47131570.0\n",
      "47131696.0\n",
      "47131824.0\n",
      "47131948.0\n",
      "47132064.0\n",
      "47132196.0\n",
      "47132320.0\n",
      "47132450.0\n",
      "47132572.0\n",
      "47132708.0\n",
      "47132824.0\n",
      "47132956.0\n",
      "47133080.0\n",
      "47133210.0\n",
      "47133336.0\n",
      "47133456.0\n",
      "47133590.0\n",
      "47133716.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "N,D,H=64,1000,100\n",
    "x= tf.placeholder(tf.float32,shape=(N,D))\n",
    "y= tf.placeholder(tf.float32,shape=(N,D))\n",
    "\n",
    "w1= tf.placeholder(tf.float32,shape=(D,H))\n",
    "w2= tf.placeholder(tf.float32,shape=(H,D))\n",
    "h=tf.maximum(tf.matmul(x,w1),0)\n",
    "\n",
    "y_pred=tf.matmul(h,w2)\n",
    "diff=y_pred-y\n",
    "loss=tf.reduce_mean(tf.reduce_sum(diff**2,axis=1))\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "with tf.Session() as sess:\n",
    "    values ={x:np.random.randn(N,D),\n",
    "             w1:np.random.randn(D,H),\n",
    "             w2:np.random.randn(H,D),\n",
    "             y:np.random.randn(N,D)}\n",
    "    learning_rate= 1e-5\n",
    "    for t in range(50):\n",
    "        out=sess.run(loss,feed_dict=values) \n",
    "        loss_val=out\n",
    "        values[w1] -=learning_rate *grad_w1_val\n",
    "        values[w2] -=learning_rate *grad_w2_val\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n",
      "[47846200.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "N,D,H=64,1000,100\n",
    "x= tf.placeholder(tf.float32,shape=(N,D))\n",
    "y= tf.placeholder(tf.float32,shape=(N,D))\n",
    "\n",
    "w1=tf.Variable(tf.random.normal((D,H)))\n",
    "w2=tf.Variable(tf.random.normal((H,D)))\n",
    "\n",
    "h=tf.maximum(tf.matmul(x,w1),0)\n",
    "y_pred=tf.matmul(h,w2)\n",
    "diff=y_pred-y\n",
    "loss=tf.reduce_mean(tf.reduce_sum(diff**2,axis=1))\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "learning_rate = 1e-5\n",
    "new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values ={x:np.random.randn(N,D),\n",
    "             y:np.random.randn(N,D)}\n",
    "    for t in range(50):\n",
    "        loss_val  =sess.run([loss],feed_dict=values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46603104.0\n",
      "16983216.0\n",
      "8874668.0\n",
      "5184410.5\n",
      "3236239.0\n",
      "2112869.0\n",
      "1424823.8\n",
      "984633.44\n",
      "693148.75\n",
      "495150.28\n",
      "358226.06\n",
      "261741.7\n",
      "193000.48\n",
      "143366.19\n",
      "107327.45\n",
      "80874.49\n",
      "61302.965\n",
      "46703.22\n",
      "35780.277\n",
      "27554.62\n",
      "21336.568\n",
      "16613.828\n",
      "13015.793\n",
      "10264.811\n",
      "8156.3716\n",
      "6534.3213\n",
      "5285.6772\n",
      "4321.615\n",
      "3576.1387\n",
      "2998.4995\n",
      "2549.574\n",
      "2200.9824\n",
      "1929.8245\n",
      "1718.5815\n",
      "1553.8113\n",
      "1425.1455\n",
      "1324.6362\n",
      "1246.1655\n",
      "1184.8163\n",
      "1136.9009\n",
      "1099.4775\n",
      "1070.245\n",
      "1047.4717\n",
      "1029.7004\n",
      "1015.881\n",
      "1005.1359\n",
      "996.8783\n",
      "990.53705\n",
      "985.7109\n",
      "982.01794\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "N,D,H=64,1000,100\n",
    "x= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "y= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "\n",
    "w1=tf.Variable(tf.random.normal((D,H)))\n",
    "w2=tf.Variable(tf.random.normal((H,D)))\n",
    "\n",
    "h=tf.maximum(tf.matmul(x,w1),0)\n",
    "y_pred=tf.matmul(h,w2)\n",
    "diff=y_pred-y\n",
    "loss=tf.reduce_mean(tf.reduce_sum(diff**2,axis=1))\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "learning_rate = 1e-5\n",
    "new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n",
    "updates = tf.group(new_w1,new_w2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values ={x:np.random.randn(N,D),\n",
    "             y:np.random.randn(N,D)}\n",
    "    for t in range(50):\n",
    "        loss_val ,_ =sess.run([loss,updates],feed_dict=values)\n",
    "        print (loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51568544.0\n",
      "17851804.0\n",
      "9272588.0\n",
      "5398702.0\n",
      "3365161.0\n",
      "2198038.8\n",
      "1485759.2\n",
      "1030848.7\n",
      "730046.0\n",
      "525593.6\n",
      "383698.34\n",
      "283196.44\n",
      "211018.98\n",
      "158612.61\n",
      "120059.625\n",
      "91523.266\n",
      "70183.75\n",
      "54142.688\n",
      "42000.887\n",
      "32754.666\n",
      "25677.012\n",
      "20232.834\n",
      "16026.506\n",
      "12766.1455\n",
      "10232.6875\n",
      "8256.282\n",
      "6712.41\n",
      "5503.34\n",
      "4554.133\n",
      "3807.1719\n",
      "3218.0535\n",
      "2753.1333\n",
      "2385.504\n",
      "2094.3694\n",
      "1863.4016\n",
      "1680.1191\n",
      "1534.5294\n",
      "1418.7562\n",
      "1326.6249\n",
      "1253.0013\n",
      "1194.4812\n",
      "1147.9104\n",
      "1110.8251\n",
      "1081.2346\n",
      "1057.6418\n",
      "1038.8694\n",
      "1023.9444\n",
      "1012.06555\n",
      "1002.6411\n",
      "995.1684\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "N,D,H=64,1000,100\n",
    "x= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "y= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "\n",
    "w1=tf.Variable(tf.random.normal((D,H)))\n",
    "w2=tf.Variable(tf.random.normal((H,D)))\n",
    "\n",
    "h=tf.maximum(tf.matmul(x,w1),0)\n",
    "y_pred=tf.matmul(h,w2)\n",
    "diff=y_pred-y\n",
    "loss=tf.reduce_mean(tf.reduce_sum(diff**2,axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "updates = optimizer.minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values ={x:np.random.randn(N,D),\n",
    "             y:np.random.randn(N,D)}\n",
    "    for t in range(50):\n",
    "        loss_val ,_ =sess.run([loss,updates],feed_dict=values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52604.758\n",
      "52552.297\n",
      "52499.902\n",
      "52447.594\n",
      "52395.367\n",
      "52343.207\n",
      "52291.14\n",
      "52239.15\n",
      "52187.234\n",
      "52135.4\n",
      "52083.65\n",
      "52031.97\n",
      "51980.375\n",
      "51928.855\n",
      "51877.42\n",
      "51826.05\n",
      "51774.77\n",
      "51723.56\n",
      "51672.434\n",
      "51621.375\n",
      "51570.4\n",
      "51519.49\n",
      "51468.664\n",
      "51417.92\n",
      "51367.258\n",
      "51316.656\n",
      "51266.137\n",
      "51215.69\n",
      "51165.32\n",
      "51115.023\n",
      "51064.81\n",
      "51014.664\n",
      "50964.594\n",
      "50914.586\n",
      "50864.67\n",
      "50814.824\n",
      "50765.055\n",
      "50715.35\n",
      "50665.727\n",
      "50616.176\n",
      "50566.695\n",
      "50517.293\n",
      "50467.957\n",
      "50418.7\n",
      "50369.52\n",
      "50320.4\n",
      "50271.367\n",
      "50222.4\n",
      "50173.52\n",
      "50124.71\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "N,D,H=64,1000,100\n",
    "x= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "y= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "\n",
    "w1=tf.Variable(tf.random.normal((D,H)))\n",
    "w2=tf.Variable(tf.random.normal((H,D)))\n",
    "\n",
    "h=tf.maximum(tf.matmul(x,w1),0)\n",
    "y_pred=tf.matmul(h,w2)\n",
    "loss= tf.losses.mean_squared_error(y_pred,y)\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "updates = optimizer.minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values ={x:np.random.randn(N,D),\n",
    "             y:np.random.randn(N,D)}\n",
    "    for t in range(50):\n",
    "        loss_val ,_ =sess.run([loss,updates],feed_dict=values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002CF7F952FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002CF7F952FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002CF7F952FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002CF7F952FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002CF7DE48CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002CF7DE48CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002CF7DE48CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002CF7DE48CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "9.037378\n",
      "6.95628\n",
      "5.466412\n",
      "4.382002\n",
      "3.5818348\n",
      "2.9846504\n",
      "2.5345216\n",
      "2.192185\n",
      "1.9299331\n",
      "1.7275461\n",
      "1.570395\n",
      "1.4476819\n",
      "1.3514802\n",
      "1.275767\n",
      "1.2159235\n",
      "1.1684372\n",
      "1.1306646\n",
      "1.100476\n",
      "1.0763459\n",
      "1.0570719\n",
      "1.0416536\n",
      "1.0292693\n",
      "1.0193359\n",
      "1.0113343\n",
      "1.0049025\n",
      "0.99972814\n",
      "0.9955923\n",
      "0.9922526\n",
      "0.9895636\n",
      "0.9873988\n",
      "0.985657\n",
      "0.98425394\n",
      "0.9831186\n",
      "0.9822084\n",
      "0.9814748\n",
      "0.9808823\n",
      "0.98040235\n",
      "0.98001033\n",
      "0.97969073\n",
      "0.9794331\n",
      "0.9792218\n",
      "0.9790479\n",
      "0.9789041\n",
      "0.97878236\n",
      "0.9786732\n",
      "0.97858274\n",
      "0.9785073\n",
      "0.97844374\n",
      "0.9783896\n",
      "0.9783437\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "N,D,H=64,1000,100\n",
    "x= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "y= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "\n",
    "init = tf.variance_scaling_initializer(4.0)\n",
    "h = tf.layers.dense(inputs=x,units=H ,activation=tf.nn.relu,kernel_initializer=init)\n",
    "y_pred = tf.layers.dense(inputs=h,units=D,kernel_initializer=init)\n",
    "loss= tf.losses.mean_squared_error(y_pred,y)\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-1)\n",
    "updates = optimizer.minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values ={x:np.random.randn(N,D),y:np.random.randn(N,D)}\n",
    "    for t in range(50):\n",
    "        loss_val ,_=sess.run([loss,updates],feed_dict=values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1617022\n",
      "1.1617019\n",
      "1.1617014\n",
      "1.161701\n",
      "1.1617007\n",
      "1.1617002\n",
      "1.1616997\n",
      "1.1616994\n",
      "1.1616989\n",
      "1.1616985\n",
      "1.1616982\n",
      "1.1616977\n",
      "1.1616973\n",
      "1.161697\n",
      "1.1616966\n",
      "1.1616963\n",
      "1.1616958\n",
      "1.1616954\n",
      "1.161695\n",
      "1.1616945\n",
      "1.1616943\n",
      "1.1616938\n",
      "1.1616933\n",
      "1.1616931\n",
      "1.1616926\n",
      "1.1616921\n",
      "1.1616919\n",
      "1.1616914\n",
      "1.161691\n",
      "1.1616907\n",
      "1.1616902\n",
      "1.1616899\n",
      "1.1616893\n",
      "1.161689\n",
      "1.1616886\n",
      "1.1616883\n",
      "1.161688\n",
      "1.1616875\n",
      "1.1616873\n",
      "1.1616868\n",
      "1.1616863\n",
      "1.1616861\n",
      "1.1616857\n",
      "1.1616853\n",
      "1.1616849\n",
      "1.1616843\n",
      "1.161684\n",
      "1.1616836\n",
      "1.1616833\n",
      "1.1616828\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "N,D,H=64,1000,100\n",
    "x= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "y= tf.placeholder(tf.float32 , shape=(N,D))\n",
    "\n",
    "model =tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(H,input_shape=(D,),activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(D))\n",
    "y_pred = model(x)\n",
    "loss= tf.losses.mean_squared_error(y_pred,y)\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "updates = optimizer.minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values ={x:np.random.randn(N,D),y:np.random.randn(N,D)}\n",
    "    for t in range(50):\n",
    "        loss_val ,_=sess.run([loss,updates],feed_dict=values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "64/64 [==============================] - 1s 16ms/sample - loss: 1.1799\n",
      "Epoch 2/50\n",
      "64/64 [==============================] - 0s 317us/sample - loss: 1.1388\n",
      "Epoch 3/50\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 1.1070\n",
      "Epoch 4/50\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 1.0818\n",
      "Epoch 5/50\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 1.0613\n",
      "Epoch 6/50\n",
      "64/64 [==============================] - 0s 141us/sample - loss: 1.0444\n",
      "Epoch 7/50\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 1.0302\n",
      "Epoch 8/50\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 1.0182\n",
      "Epoch 9/50\n",
      "64/64 [==============================] - 0s 141us/sample - loss: 1.0080\n",
      "Epoch 10/50\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 0.9991\n",
      "Epoch 11/50\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.9914\n",
      "Epoch 12/50\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 0.9847\n",
      "Epoch 13/50\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9787\n",
      "Epoch 14/50\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 0.9734\n",
      "Epoch 15/50\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.9686\n",
      "Epoch 16/50\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.9642\n",
      "Epoch 17/50\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 0.9602\n",
      "Epoch 18/50\n",
      "64/64 [==============================] - 0s 141us/sample - loss: 0.9566\n",
      "Epoch 19/50\n",
      "64/64 [==============================] - 0s 141us/sample - loss: 0.9532\n",
      "Epoch 20/50\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.9501\n",
      "Epoch 21/50\n",
      "64/64 [==============================] - 0s 453us/sample - loss: 0.9471\n",
      "Epoch 22/50\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9443\n",
      "Epoch 23/50\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 0.9416\n",
      "Epoch 24/50\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9391\n",
      "Epoch 25/50\n",
      "64/64 [==============================] - 0s 141us/sample - loss: 0.9366\n",
      "Epoch 26/50\n",
      "64/64 [==============================] - 0s 328us/sample - loss: 0.9342\n",
      "Epoch 27/50\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9318\n",
      "Epoch 28/50\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.9294\n",
      "Epoch 29/50\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 0.9271\n",
      "Epoch 30/50\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9248\n",
      "Epoch 31/50\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 0.9225\n",
      "Epoch 32/50\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 0.9203\n",
      "Epoch 33/50\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9180\n",
      "Epoch 34/50\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.9157\n",
      "Epoch 35/50\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.9134\n",
      "Epoch 36/50\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 0.9111\n",
      "Epoch 37/50\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 0.9088\n",
      "Epoch 38/50\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.9064\n",
      "Epoch 39/50\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 0.9041\n",
      "Epoch 40/50\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 0.9017\n",
      "Epoch 41/50\n",
      "64/64 [==============================] - 0s 437us/sample - loss: 0.8993\n",
      "Epoch 42/50\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.8968\n",
      "Epoch 43/50\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.8943\n",
      "Epoch 44/50\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.8918\n",
      "Epoch 45/50\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.8893\n",
      "Epoch 46/50\n",
      "64/64 [==============================] - 0s 344us/sample - loss: 0.8867\n",
      "Epoch 47/50\n",
      "64/64 [==============================] - 0s 328us/sample - loss: 0.8841\n",
      "Epoch 48/50\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 0.8815\n",
      "Epoch 49/50\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 0.8788\n",
      "Epoch 50/50\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.8761\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "N,D,H=64,1000,100\n",
    "model =tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(H,input_shape=(D,),activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(D))\n",
    "model.compile(loss=tf.keras.losses.mean_squared_error,optimizer=tf.keras.optimizers.SGD(lr=1e0))\n",
    "x=np.random.randn(N,D)\n",
    "y=np.random.randn(N,D)\n",
    "history=model.fit(x,y,epochs =50 ,batch_size=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNlab2020",
   "language": "python",
   "name": "nnlab2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
